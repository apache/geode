---
title:  Setting Socket Buffer Sizes
---

<!--
Licensed to the Apache Software Foundation (ASF) under one or more
contributor license agreements.  See the NOTICE file distributed with
this work for additional information regarding copyright ownership.
The ASF licenses this file to You under the Apache License, Version 2.0
(the "License"); you may not use this file except in compliance with
the License.  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.
-->

When you determine buffer size settings, you must strike a balance between communication needs and other processing.

Larger socket buffers allow your members to distribute data and events more quickly, but they also take memory away from other things. If you store very large data objects in your cache, finding the right sizing for your buffers while leaving enough memory for the cached data can become critical to system performance.

Ideally, you should have buffers large enough for the distribution of any single data object so you don’t get message fragmentation, which lowers performance. Your buffers should be at least as large as your largest stored objects and their keys plus some overhead for message headers. The overhead varies depending on who is sending and receiving, but 100 bytes should be sufficient. You can also look at the statistics for the communication between your processes to see how many bytes are being sent and received.

If you see performance problems and logging messages indicating blocked writers, increasing your buffer sizes may help.

This table lists the settings for the various member relationships and protocols, and tells where to set them.

<table>
<colgroup>
<col width="33%" />
<col width="33%" />
<col width="34%" />
</colgroup>
<thead>
<tr class="header">
<th>Protocol / Area Affected</th>
<th>Configuration Location</th>
<th>Property Name</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>TCP / IP</strong></td>
<td>---</td>
<td>---</td>
</tr>
<tr>
<td>Peer-to-peer send/receive</td>
<td><p>gemfire.properties</p></td>
<td>socket-buffer-size</td>
</tr>
<tr>
<td>Client send/receive</td>
<td><p>cache.xml &lt;pool&gt;</p></td>
<td>socket-buffer-size</td>
</tr>
<tr>
<td>Server send/receive</td>
<td><code class="ph codeph">gfsh start server</code> or
<p>cache.xml &lt;CacheServer&gt;</p></td>
<td>socket-buffer-size</td>
</tr>
<tr>
<td><strong>UDP Multicast</strong></td>
<td>---</td>
<td>---</td>
</tr>
<tr>
<td>Peer-to-peer send</td>
<td>gemfire.properties</td>
<td>mcast-send-buffer-size</td>
</tr>
<tr>
<td>Peer-to-peer receive</td>
<td>gemfire.properties</td>
<td>mcast-recv-buffer-size</td>
</tr>
<tr>
<td><strong>UDP Unicast</strong></td>
<td>---</td>
<td>---</td>
</tr>
<tr>
<td>Peer-to-peer send</td>
<td>gemfire.properties</td>
<td>udp-send-buffer-size</td>
</tr>
<tr>
<td>Peer-to-peer receive</td>
<td>gemfire.properties</td>
<td>udp-recv-buffer-size</td>
</tr>
</tbody>
</table>

**TCP/IP Buffer Sizes**

If possible, your TCP/IP buffer size settings should match across your <%=vars.product_name%> installation. At a minimum, follow the guidelines listed here.

-   **Peer-to-peer**. The socket-buffer-size setting in `gemfire.properties` should be the same throughout your cluster.
-   **Client/server**. The client’s pool socket-buffer size-should match the setting for the servers the pool uses, as in these example `cache.xml` snippets:

    ``` pre
    Client Socket Buffer Size cache.xml Configuration:
    <pool>name="PoolA" server-group="dataSetA" socket-buffer-size="42000"...

    Server Socket Buffer Size cache.xml Configuration:
    <cache-server port="40404" socket-buffer-size="42000">
        <group>dataSetA</group>
    </cache-server>
    ```

**UDP Multicast and Unicast Buffer Sizes**

With UDP communication, one receiver can have many senders sending to it at once. To accommodate all of the transmissions, the receiving buffer should be larger than the sum of the sending buffers. If you have a system with at most five members running at any time, in which all members update their data regions, you would set the receiving buffer to at least five times the size of the sending buffer. If you have a system with producer and consumer members, where only two producer members ever run at once, the receiving buffer sizes should be set at over two times the sending buffer sizes, as shown in this example:

``` pre
mcast-send-buffer-size=42000
mcast-recv-buffer-size=90000
udp-send-buffer-size=42000
udp-recv-buffer-size=90000
```

**Operating System Limits**

Your operating system sets limits on the buffer sizes it allows. If you request a size larger than the allowed, you may get warnings or exceptions about the setting during startup. These are two examples of the type of message you may see:

``` pre
[warning 2008/06/24 16:32:20.286 PDT CacheRunner <main> tid=0x1]
requested multicast send buffer size of 9999999 but got 262144: see 
system administration guide for how to adjust your OS 

Exception in thread "main" java.lang.IllegalArgumentException: Could not 
set "socket-buffer-size" to "99262144" because its value can not be 
greater than "20000000".
```

If you think you are requesting more space for your buffer sizes than your system allows, check with your system administrator about adjusting the operating system limits.


